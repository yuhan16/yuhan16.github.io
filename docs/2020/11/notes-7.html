<!DOCTYPE html>
<html>
    <head>

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width initial-scale=1">

<meta property="og:title" content="Markov Chain">
<title>Markov Chain</title>
<meta property="og:description" content="This note reviews the basics of Markov chains.">
<meta property="og:url" content="http://localhost:4000/2020/11/notes-7.html">
<meta property="og:site_name" content="HuskyDev">
<meta property="og:locale" content="">

<meta name="keywords" content="YuhanHuskyDev">

<link rel="icon" href="/assets/images/favicon.ico"/>
<link rel="shortcut icon" href="/assets/images/favicon.ico" />
<link rel="stylesheet" href="/assets/css/main.css"/>
<link rel="canonical" href="http://localhost:4000/2020/11/notes-7.html"/>
<link rel="alternate" type="application/atom+xml" title="HuskyDev" href="http://localhost:4000/feed.xml" />

<!--script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script-->
<script src="https://kit.fontawesome.com/e49cc00366.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css">


<link rel="stylesheet" href="/assets/css/github.min.css">
<script src="/assets/js/highlight.min.js"></script>
<script>hljs.highlightAll();</script>

<!--script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ['\\(','\\)'] ],
        displayMath: [ ['$$', '$$'], ['\\[', '\\]'] ],
        processEscapes: true
      },
      "HTML-CSS": { scale: 90 }
    });
</script-->
<!--script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script-->
<!--script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML"></script-->


<script>
MathJax = {
  tex: {
    inlineMath: [ ['$','$'], ['\\(','\\)'] ],
    displayMath: [ ['$$', '$$'], ['\\[', '\\]'] ],
    processEscapes: true,
    autoload: {
      color: [],
      colorv2: ['color']
    },
    packages: {'[+]': ['noerrors']}
  },
  chtml: {
    scale: 0.9
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
  loader: {
    load: ['[tex]/noerrors']
  } 
};
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script src="/assets/js/myjavascript.js"></script>
    
</head>




<body>
    
    <nav class="navbar">
    <div class="navbar-container">
        <!--Navbar logo-->
        <a href="/"><img src="/assets/images/husky_logo.png" class="navbar-logo"></a>

        <!--Navbar menu-->
        <ul class="main-menu">
            
                
                    <li><a href="/">Home</a></li>
                
            
                
                    <li><a href="/blog">Blog</a></li>
                
            
                
                    <li><a href="/publications">Publications</a></li>
                
            
                
                    <li><a href="/archives">Archives</a></li>
                
            
            
            <li><a href="javascript:void(0)"><i class="fa fa-search"></i></a></li>
        </ul>
    </div>
    </nav>


	<div class="card-container"><!--default_1 is single card layout, sutiable for pages like aboutme, tags, categories, require only one card to display content-->
        <div class="card">
            <div class="post">
    <h1 class="post-title">Markov Chain</h1>
	
	<!--pose meta data-->
	<div style="display: flex; gap: 10px; margin-bottom: 1rem;">
		<span class="post-meta">
			<i class="fa-regular fa-calendar-check">&nbsp;</i>2020-11-13
		</span>

		<span class="post-meta">
			<i class="fa-regular fa-folder-open"></i>&nbsp;<a href="/categories/probability">Probability</a>
		</span>

		<span class="post-meta">
			<i class="fa-regular fa-clock"></i>&nbsp;
		</span>

        <!--span class="post-meta">
			<i class="fas fa-tags"></i>&nbsp;
            
                
                <a href="/tags/#notes">notes,</a>
                
            
                
                <a href="/tags/#math">math</a>
                
            
		</span-->
	</div>

	<!--table of content-->
	<div class="toc">
		<p class="toc-meta">Table of Contents</p>
		<div class="toc-content">
			
		</div>
	</div>
    
	<!--post content-->
    <article class="post-content">
        <p>Most of our study of probability has dealt with independent trials processes, in which we have i.i.d. random variables $X_i$. This is useful for modeling and sampling situations. But when study random dynamical systems, they are less useful. In these cases, ${X_i}$ are no longer independent because they are all part of the system, and they have to interact with each other. So one way to modeling this is to use conditional probability.</p>

<h2 id="markov-chains-basic-definitions">Markov chains: basic definitions</h2>
<p>Consider a countable sequence $X_1, X_2, \dots, X_n, \dots$ which</p>
<ul>
    <li> the subscript represents time, thus we have discrete time sequence;</li>
    <li> each $X_i$ has finite outcomes.</li>
</ul>
<p>In other words, each $X_i$ is a discrete random variable that takes one of $N$ possible values, where 
$N = \mathbf{card}(S)$ and $S$ is the outcome space; it may be the case that $N = \infty$.</p>

<div class="theorem"><p><b>Definition.</b> 
The process $X$ is a Markov chain if it satisfies the <b>Markov condition</b>:
$$\begin{equation}
    \mathbf{P}\left(X_{n}=s | X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n-1}=x_{n-1}\right)=\mathbf{P}\left(X_{n}=s | X_{n-1}=x_{n-1}\right)
\end{equation}$$
for all $n\geq 1$ ans all $s, x_1, \dots, x_{n-1} \in S$.
</p></div>
<p>Since $S$ is assumed countable, it can be put in one-to-one correspondence with some subset $S’$ of the integers, and without loss of generality we can assume that $S$ is this set $S’$ of integers. Then the evolution of a chain is described by its <strong>transition probabilities</strong> 
\(\begin{equation}
    \label{eq:7.1}
    \tag{7-1}
    \mathbf{P}(X_{n} = j \;\vert\; X_{n-1} = i) := p_{ij}(n-1).
\end{equation}\)</p>

<div class="theorem"><p><b>Theorem.</b> 
The transition matrix $P$ is a **stochastic matrix**, which is to say that: 
<ol>
    <li> $P$ has non-negative entries, or $p_{ij} \geq 0$ for all $i, j$,</li>
    <li> $P$ has row sums equal to one, or $\sum_j p_{ij} = 1$ for all $i$.</li>
</ol>
</p></div>

<p>%Note that the Markov property is equivalent to the following stipulation, which is also called <strong>$k$-step transition probabilities</strong>.</p>

<div class="theorem"><p><b>Definition.</b> 
The **$k$-step transition probabilities** is defined as
$$\begin{equation}
    \label{eq:7.2}
    \tag{7-2}
    \mathbf{P}(X_{n+k-1} = j \;\vert\; X_{n-1} = i) := p_{ij}^{(k)}(n-1) \quad \text{for any } n, k \geq 1.
\end{equation}$$
</p></div>

<p>%Based on this, we can define</p>
<div class="theorem"><p><b>Definition.</b> 
The **transition matrix** $P(n-1) = (p_{ij}(n-1))$ is the $\left\vert S \right\vert \times \left\vert S \right\vert$ matrix of **transition probabilities** $p_{ij}(n-1)$. The **$k$-step transition matrix** $P^{(k)}(n-1) = (p_{ij}^{(k)}(n-1))$ is the matrix of **$k$-step transition probabilities** $p_{ij}^{(k)}(n-1)$.
</p></div>

<div class="remark"><p><b>Remark.</b> 
We can check that the Markov property is equivalent to each of the following two stipulations: for each $s \in S$ and for every sequence $\{ x_i \;\vert\; i \geq 0\}$ in $S$,
$$\begin{equation}
    \label{eq:7.3a}
    \tag{7-3a}
    \begin{split}
        \mathbf{P}\left(X_{n+1}=s | X_{n_{1}}=x_{n_{1}}, X_{n_{2}}=x_{n_{2}}, X_{n_{k}}=x_{n_{k}}\right)=\mathbf{P}\left(X_{n+1}=s | X_{n_{k}}=x_{n_{k}}\right) \\
        \text{for all } n_1 &lt; n_2 &lt; \cdots &lt; n_k \leq n.
    \end{split}
\end{equation}$$
$$\begin{equation}
    \label{eq:7.3b}
    \tag{7-3b}
    \begin{split}
        \mathbf{P}\left(X_{m+n}=s | X_{0}=x_{0}, X_{1}=x_{1}, \ldots, X_{m}=x_{m}\right)=\mathbf{P}\left(X_{m+n}=s | X_{m}=x_{m}\right) \\ 
        \text{for any } m, n \geq 0.
    \end{split}
\end{equation}$$
</p></div>

<p>Next we introduce another assumption:</p>
<div class="theorem"><p><b>Definition.</b> 
The chain $X$ is called **homogeneous** if
$$\begin{equation}
    \mathbf{P}(X_n = j \;\vert\; X_{n-1} = i) = \mathbf{P}(X_2 = j \;\vert\; X_1 = i), \quad \text{for all } n, i, j.
\end{equation}$$
</p></div>

<div class="remark"><p><b>Remark.</b> 
Note the following two remarks.
<ol>
    <li> Markov property and homogeneity property are **independent**. There are also Markov chains which are not homogeneous.</li>
    <li> If a Markov chain $X$ is homogeneous, then $p_{ij}(n-1)$ doesn't depends on the time $(n-1)$, i.e., the probability transition matrix $P$ is **fixed** at each step.</li>
</ol>
</p></div>

<h2 id="properties-of-markov-chains">Properties of Markov chains</h2>
<p>By the assumption of homogeneity, we know $P(n-1) = P$. That $P^{(k)}(n-1)$ doesn’t depend on $(n-1)$ is a consequence of the following important fact.</p>

<div class="theorem"><p><b>Theorem.</b> [Chapman-Kolmogorov equations]
$$\begin{equation}
    p_{ij}^{(n+r)}(m) = \sum_{k} p_{ik}^{(n)}(m) p_{kj}^{(r)}(m+n).
\end{equation}$$
Therefore, 
$$\begin{equation}
    P^{(n+r)}(m) = P^{(n)}(m) P^{(r)}(m+n).
\end{equation}$$
Furthermore, if we have homogeneity, then 
$$\begin{equation}
    P^{n}(m) = P^n,
\end{equation}$$
the $n$th power of $P$.
</p></div>

<div class="proof"><a href="javascript:void(0)" id="pf1-link"><b>Proof &#9656;</b></a>
<div class="proof-content" id="pf1-content"><p>
    $$\begin{equation}
        \begin{split}
            p_{ij}^{n+r}(m) &amp;= \mathbf{P}(X_{m+n+r} = j \;\vert\; X_m = i) \\ 
            &amp;= \sum_{k} \mathbf{P}(X_{m+n+r} = j, X_{m+n} = k \;\vert\; X_m = i) \\
            &amp;= \sum_{k} \mathbf{P}(X_{m+n+r} = j \;\vert\; X_{m+n} = k, X_m = i) \mathbf{P}(X_{m+n} = k \;\vert\; X_m = i) \quad \text{(marginalization)} \\
            &amp;= \sum_{k} \mathbf{P}(X_{m+n+r} = j \;\vert\; X_{m+n} = k) \mathbf{P}(X_{m+n} = k \;\vert\; X_m = i) \quad \text{(Markov property)} \\
            &amp;= \sum_{k} p_{kj}^{(r)}(m+n) p_{ik}^{(n)}(m) . 
        \end{split}
    \end{equation}$$
    The marginalization step uses the fact that 
    $$\begin{equation}
        \mathbf{P}(A \cap B \;\vert\; C) = \mathbf{P}(A \;\vert\; B \cap C) \mathbf{P}(B \;\vert\; C).
    \end{equation}$$
    The Markov property step uses \eqref{eq:7.3a}. The $n$th power is obtained by iteration.
&#9724;</p>
</div>
</div>
<script>toggle_proof("pf1");</script>

<p>One consequence of the preceding theorem is that $P^{(n)}(m) = P^{(n)}(0)$. Note that this consequence is obtained <strong>with homogeneous assumption</strong>. We write $P_n$ for $P^{(n)}(m)$ and $p_{ij}(n)$ for $p_{ij}^{(n)}(m)$. This theorem relates long-term development to short-term development, and tells us how $X_n$ depends on the initial variable $X_0$. Let $\mu_i^{(n)} = \mathbf{P}(X_n = i)$ be the mass function of $X_n$, and write $\mu^{(n)}$ for the <strong>row vector</strong> with entries $(\mu_i^{(n)} : i \in S)$. Then we have the following lemma.</p>

<div class="theorem"><p><b>Lemma.</b> 
$\mu^{(m+n)} = \mu^{(m)}P_n$, and hence $\mu^{(n)} = \mu^{(0)}P^n$.
</p></div>

<div class="proof"><a href="javascript:void(0)" id="pf2-link"><b>Proof &#9656;</b></a>
<div class="proof-content" id="pf2-content"><p>
    We have that
    $$\begin{equation}
        \begin{split}
            \mu_j^{(m+n)} &amp;= \mathbf{P}(X_{m+n} = j) \\
            &amp;= \sum_{i} \mathbf{P}(X_{m+n} = j \;\vert\; X_m = i) \mathbf{P}(X_m = i) \\
            &amp;= \sum_{i} \mu_i^{(m)} p_{ij}(n) \\
            &amp;= (\mu^{(m)} P_n)_j
        \end{split}
    \end{equation}$$
    and the result follows from the preceding theorem.
&#9724;</p>
</div>
</div>
<script>toggle_proof("pf2");</script>

<p>The random evolution of the chain is determined by the transition matrix $P$ and the initial mass function $\mu^{(0)}$.</p>

<h2 id="absorbing-markov-chains">Absorbing Markov chains</h2>
<p>An absorbing Markov chain is a special type of Markov chains.</p>

<div class="theorem"><p><b>Definition.</b> 
A state $s_i$ of a Markov chain is called **absorbing** if it is impossible to leave it (i.e., $p_{ii} = 1$). A Markov chain is **absorbing** if it has at least one absorbing state, and if from every state it is possible to go to an absorbing state (not necessarily in one step).
</p></div>

<div class="theorem"><p><b>Definition.</b> 
In an absorbing Markov chain, a state which is not absorbing is called **transient**.
</p></div>

<h3 id="canonical-form-of-absorbing-markov-chains">Canonical form of absorbing Markov chains</h3>
<p>Consider an arbitrary absorbing Markov chain. Renumber the states so that the transient states come first. If there are $r$ absorbing states and $t$ transient states, the transition matrix will have the following canonical form
\begin{equation}
    P = 
    \begin{blockarray}{rcc}
        &amp; TR. &amp; ABS. <br />
    \begin{block}{r[cc]}
        TR. &amp; Q &amp;  R <br />
        ABS. &amp; 0 &amp;  I <br />
    \end{block}
    \end{blockarray}
\end{equation}
Here $I$ is an $r\times r$ identity matrix, $0$ is an $r\times t$ zero matrix, $R$ is a nonzero $t\times r$ matrix, and $Q$ is an $t\times t$ matrix. The first $t$ states are transient and the last $r$ states are absorbing.</p>

<p>A standard matrix algebra argument shows that $P^n$ is of the form
\begin{equation}
    P^n = 
    \begin{blockarray}{rcc}
        &amp; TR. &amp; ABS. <br />
    \begin{block}{r[cc]}
        TR. &amp; Q^n &amp;  * <br />
        ABS. &amp; 0 &amp;  I <br />
    \end{block}
    \end{blockarray}
\end{equation}
where the asterisk $*$ stands for the $t\times r$ matrix in the upper right-hand corner of $P^n$.</p>

<p>The entries of $Q_n$ give the probabilities for being in each of the transient states after $n$ steps for each possible transient starting state. The following theorem will show that every entry of $Q_n$ will approach zero as $n$ approaches infinity (i.e., $Q_n \to 0$).</p>

<div class="theorem"><p><b>Theorem.</b> 
In an absorbing Markov chain, the probability that the process will be absorbed is 1 (i.e., $Q_n \to 0$ as $n \to \infty$).
</p></div>

<div class="proof"><a href="javascript:void(0)" id="pf3-link"><b>Proof &#9656;</b></a>
<div class="proof-content" id="pf3-content"><p>
From each non-absorbing state $s_j$ it is possible to reach an absorbing state. Let $m_j$ be the minimum number of steps required to reach an absorbing state, starting from $s_j$. Let $p_j$ be the probability that, starting from $s_j$, the process will not reach an absorbing state in $m_j$ steps. Then $p_j &lt; 1$. Let $m$ be the largest of the $m_j$ and let $p$ be the largest of $p_j$. The probability of not being absorbed in $m$ steps is less than or equal to $p$, in $2m$ steps less than or equal to $p^2$, etc. Since $p &lt; 1$, these probabilities tend to 0. Since the probability of not being absorbed in $n$ steps is monotone decreasing, these probabilities also tend to 0, hence $\lim_{n\to\infty} Q_n = 0$.
&#9724;</p>
</div>
</div>
<script>toggle_proof("pf3");</script>

<h3 id="the-fundamental-matrix">The fundamental matrix</h3>
<div class="theorem"><p><b>Definition.</b> 
For an absorbing Markov chain $P$, the matrix $N = (I-Q)^{-1}$ is called the **fundamental matrix** for $P$. The entry $n_{ij}$ of $N$ gives the expected number of times that the process is in the transient state $s_j$ if it is started in the transient state $s_i$.
</p></div>

<div class="theorem"><p><b>Theorem.</b> 
For an absorbing Markov chain the matrix $I-Q$ has an inverse $N$ and $N = I + Q + Q^2 + \cdots$. The $ij$-entry $n_{ij}$ of the matrix $N$ is the expected number of times the chain is in state $s_j$, given that it starts in state $s_i$. The initial state is counted if $i = j$.
</p></div>

<div class="proof"><a href="javascript:void(0)" id="pf4-link"><b>Proof &#9656;</b></a>
<div class="proof-content" id="pf4-content"><p>
Let $(I-Q)x = 0$; that is $x = Qx$. Then, iterating this we see that $x = Q^n x$. Since $Q_n \to 0$, we have $Q_n x \to 0$, so $x = 0$. Thus $(I-Q)^{-1} = N$
exists. Note next that
$$\begin{equation}
    (I-Q)(I+Q + Q^2 + \cdots + Q^n) = I - Q^{n+1}.
\end{equation}$$
Thus multiplying both sides by $N$ gives
$$\begin{equation}
    I + Q + Q^2 + \cdots + Q^n = N(I-Q^{n+1}) .
\end{equation}$$
Letting $n$ tend to infinity we have
$$\begin{equation}
    N = I + Q + Q^2 + \cdots .
\end{equation}$$
Let $s_i$ and $s_j$ be two transient states, and assume throughout the remainder of the proof that $i$ and $j$ are fixed. Let $X^{(k)}$ be a random variable which equals 1 if the chain is in state $s_j$ after $k$ steps, and equals 0 otherwise. For each $k$, this random variable depends upon both $i$ and $j$; we choose not to explicitly show this dependence in the interest of clarity. We have
$$\begin{equation}
    \mathbf{P} \left(X^{(k)}=1\right)=q_{i j}^{(k)},
\end{equation}$$
and 
$$\begin{equation}
    \mathbf{P} \left(X^{(k)}=0\right)=1-q_{i j}^{(k)},
\end{equation}$$
where $q_{i j}^{(k)}$ is the $ij$th entry of $Q^k$. These equations hold for $k = 0$ since $Q^0 = I$. Therefore, since $X^{(k)}$ is a 0-1 random variable, $\mathbf{E}(X^{(k)}) = q_{i j}^{(k)}$.

The expected number of times the chain is in state $s_j$ in the first $n$ steps, given that it starts in state $s_i$, is clearly
$$\begin{equation}
    \mathbf{E}\left(X^{(0)}+X^{(1)}+\cdots+X^{(n)}\right)=q_{i j}^{(0)}+q_{i j}^{(1)}+\cdots+q_{i j}^{(n)}.
\end{equation}$$
Letting $n$ tend to infinity we have
$$\begin{equation}
    \mathbf{E}\left(X^{(0)}+X^{(1)}+\cdots\right)=q_{i j}^{(0)}+q_{i j}^{(1)}+\cdots=n_{i j}.
\end{equation}$$
&#9724;</p>
</div>
</div>
<script>toggle_proof("pf4");</script>

<h3 id="time-to-absorption">Time to absorption</h3>
<p>Given that the chain starts in state $s_i$, what is the expected number of steps before the chain is absorbed? The following theorem gives the answer.</p>
<div class="theorem"><p><b>Theorem.</b> 
Let $t_i$ be the expected number of steps before the chain is absorbed, given that the chain starts in state $s_i$, and let $t$ be the **column vector** whose $i$th entry is $t_i$. Then
$$\begin{equation}
    t = N \mathbf{1}
\end{equation}$$
where $\mathbf{1}$ is a column vector all of whose entries are 1.
</p></div>

<div class="proof"><a href="javascript:void(0)" id="pf5-link"><b>Proof &#9656;</b></a>
<div class="proof-content" id="pf5-content"><p>
If we add all the entries in the $i$th row of $N$, we will have the expected number of times in any of the transient states for a given starting state $s_i$, that is, the expected time required before being absorbed. Thus, $t_i$ is the sum of the entries in the $i$th row of $N$. If we write this statement in matrix form, we obtain the theorem.
\end{proof}&#9724;</p>
</div>
</div>
<script>toggle_proof("pf5");</script>

<h3 id="absorption-probabilities">Absorption probabilities</h3>
<div class="theorem"><p><b>Theorem.</b> 
Let $b_{ij}$ be the probability that an absorbing chain will be absorbed in the absorbing state $s_j$ if it starts in the transient state $s_i$. Let $B$ be the matrix with entries $b_{ij}$ . Then $B$ is an $t\times r$ matrix, and
$$\begin{equation}
    B = NR,
\end{equation}$$
where $N$ is the fundamental matrix and $R$ is as in the canonical form.
</p></div>

<div class="proof"><a href="javascript:void(0)" id="pf6-link"><b>Proof &#9656;</b></a>
<div class="proof-content" id="pf6-content"><p>
We have 
$$\begin{equation}
    \begin{aligned} 
        B_{i j} &amp;=\sum_{n} \sum_{k} q_{i k}^{(n)} r_{k j} \\ &amp;=\sum_{k} \sum_{n} q_{i k}^{(n)} r_{k j} \\ &amp;=\sum_{k} n_{i k} r_{k j} \\ &amp;=(N R)_{i j}.
    \end{aligned}
\end{equation}$$
This completes the proof.
&#9724;</p>
</div>
</div>
<script>toggle_proof("pf6");</script>


    </article>

    <!--additional addons-->
    <hr style="height: 1px; margin: 1rem 0">
    <!--span class="level-item"><i class="far fa-clock"></i>&nbsp;8 minutes read (About 1210 words)</span-->
	<div class="post-meta" style="display: flex; justify-content: space-between; align-items: center;">
		<span>
			<i class="fas fa-tags"></i>&nbsp;
            
                
                <a href="/tags/notes">notes,</a>
                
            
                
                <a href="/tags/math">math</a>
                
            
		</span>
	</div>

</div>


<section class="post-pagination">
    
        <a href="/2020/11/notes-6-1.html">Previous: Generating Functions</a>
    

    
        <a href="/2020/11/notes-8.html">Next: Markov Chain 2</a>
    
</section>
  

<a onclick="topFunction()" id="back-top-button"><i class="fa-solid fa-chevron-up fa-2x"></i></a>


<script>
let mybutton = document.getElementById("back-top-button");	// get the button
window.onscroll = function() {scrollFunction()};	// show the button when scrolls down 200px from the top

function scrollFunction() {
  	if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
    	mybutton.style.display = "block";
  	} 
	else {
    	mybutton.style.display = "none";
  	}
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
  	document.body.scrollTop = 0;
  	document.documentElement.scrollTop = 0;
}
</script>


<script>
    var coll = document.getElementsByClassName("toc-meta");
    var i;
    
    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("toc-active");
        var content = this.nextElementSibling;  	// Note the collapsible content should right after the collapsible class.
        if (content.style.maxHeight){
          	content.style.maxHeight = null;
        } else {
        	content.style.maxHeight = content.scrollHeight + "px";
        } 
      });
    }
    </script>
        </div>
	</div>

    <footer class="footerbar">
    <div class="footerbar-container footerbar-content">
        &copy; 2024 <a href="/">HuskyDev</a> 
        <span style="padding-left:30px"></span>
        Powered by <a href="https://jekyllrb.com/">Jekyll</a>
    </div>
</footer>
</body>

</html>
